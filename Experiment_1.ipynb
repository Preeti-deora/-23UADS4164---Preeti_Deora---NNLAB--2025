{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81455813-457d-41a0-a690-4be3e1f6da32",
   "metadata": {},
   "source": [
    "**Objective**:\n",
    "WAP to implement the Perceptron Learning Algorithm using numpy in Python. \n",
    "Evaluate performance of a single perceptron for NAND and XOR truth tables as input\r\n",
    "dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e360b6-f245-4a53-a1a3-531e48dfc98e",
   "metadata": {},
   "source": [
    "**Model Description**:\n",
    "1. Input & Output:\n",
    "   The perceptron takes two binary inputs (0 or 1).\n",
    "   It produces a single binary output (0 or 1).\n",
    "2. Learning Rule:\n",
    "   Uses the Perceptron Learning Algorithm (updates weights based on errors).\n",
    "   Weight update rule:\n",
    "   ð‘Š = ð‘Š + learningÂ rate Ã— error Ã— ð‘‹\n",
    "   ð‘ = ð‘ + learningÂ rate Ã— error\n",
    "3. Activation Function:\n",
    "   Uses a Step Function:\n",
    "           ð‘“(ð‘¥) = 1 ifÂ ð‘¥â‰¥0, 0Â otherwise\n",
    "4. Training Process:\n",
    "   The model starts with random weights and bias.\n",
    "   It learns using the Perceptron Learning Algorithm.\n",
    "   Updates weights at each step to minimize classification errors.\n",
    "5. Hyperparameters:\n",
    "    Learning Rate (lr): Determines how much weights are updated in each step.\n",
    "     Default: 0.1 (can be adjusted).\n",
    "    Epochs: Number of times the perceptron iterates through the entire dataset.\n",
    "     Default: 10 (more epochs = better learning).\n",
    "Limitations:\n",
    "\n",
    "A single-layer perceptron can solve linearly separable problems (e.g., NAND).\n",
    "It cannot solve non-linearly separable problems like XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ab28ca-c53e-4630-912b-d9a85ae1d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9474d8-a4c9-4f3c-9e8f-345e01f5fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def step_function(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction function\"\"\"\n",
    "        return np.array([self.step_function(np.dot(x, self.weights) + self.bias) for x in X])\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train Perceptron using Perceptron Learning Algorithm\"\"\"\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                y_pred = self.step_function(np.dot(X[i], self.weights) + self.bias)\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]  # Update weights\n",
    "                self.bias += self.lr * error  # Update bias\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        correct = np.sum(predictions == y)\n",
    "        return correct / len(y) * 100  # Accuracy in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f420dbf-e2b5-4c9a-9b67-debf4cc6d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAND Dataset (Linearly Separable)\n",
    "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_nand = np.array([1, 1, 1, 0])  # NAND Truth Table\n",
    "\n",
    "# XOR Dataset (Not Linearly Separable)\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0])  # XOR Truth Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416f5b39-97a4-4d5d-8cdf-0ac643686758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Perceptron on NAND\n",
    "perceptron_nand = Perceptron(input_size=2, learning_rate=0.1, epochs=100)\n",
    "perceptron_nand.train(X_nand, y_nand)\n",
    "\n",
    "# Train Perceptron on XOR\n",
    "perceptron_xor = Perceptron(input_size=2, learning_rate=0.1, epochs=100)\n",
    "perceptron_xor.train(X_xor, y_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4c0c6a-6df8-4daa-a06d-dbf48fe41a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAND Predictions:\n",
      "Input: [0 0], Output: 1\n",
      "Input: [0 1], Output: 1\n",
      "Input: [1 0], Output: 1\n",
      "Input: [1 1], Output: 0\n",
      "\n",
      "XOR Predictions:\n",
      "Input: [0 0], Output: 1\n",
      "Input: [0 1], Output: 1\n",
      "Input: [1 0], Output: 0\n",
      "Input: [1 1], Output: 0\n"
     ]
    }
   ],
   "source": [
    "# Test NAND Predictions\n",
    "print(\"\\nNAND Predictions:\")\n",
    "for x in X_nand:\n",
    "    print(f\"Input: {x}, Output: {perceptron_nand.predict([x])[0]}\")\n",
    "\n",
    "# Test XOR Predictions\n",
    "print(\"\\nXOR Predictions:\")\n",
    "for x in X_xor:\n",
    "    print(f\"Input: {x}, Output: {perceptron_xor.predict([x])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61b76e8-f420-4234-991f-b8c12b56a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAND Perceptron Accuracy: 100.00%\n",
      "XOR Perceptron Accuracy: 50.00% (Fails for XOR)\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "nand_accuracy = perceptron_nand.accuracy(X_nand, y_nand)\n",
    "xor_accuracy = perceptron_xor.accuracy(X_xor, y_xor)\n",
    "\n",
    "print(f\"\\nNAND Perceptron Accuracy: {nand_accuracy:.2f}%\")\n",
    "print(f\"XOR Perceptron Accuracy: {xor_accuracy:.2f}% (Fails for XOR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d348dd-bc06-4470-b3f4-90e73dfbdd9d",
   "metadata": {},
   "source": [
    "**Description of the Code**\n",
    "1. Class: Perceptron\n",
    "   __init__ â†’ Initializes random weights and bias.\n",
    "   activation â†’ Implements step function.\n",
    "   predict â†’ Computes weighted sum and applies the activation function.\n",
    "   train â†’ Uses Perceptron Learning Algorithm to update weights.\n",
    "   evaluate â†’ Computes final accuracy after training.\n",
    "2. Training on NAND and XOR\n",
    "   We train separate perceptron models for NAND and XOR.\n",
    "   The training prints accuracy at each epoch to track progress.\n",
    "   Final accuracy is displayed at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108fee60-ab67-4a97-91ba-a17e674b9fe8",
   "metadata": {},
   "source": [
    "1. Why Does NAND Work But XOR Fails?\n",
    "  NAND is linearly separable â†’ A single perceptron can solve it. \n",
    "  XOR is not linearly separable â†’ A single perceptron cannot solve it.\n",
    "\n",
    "2. How to Fix XOR?\n",
    "  Use a Multi-Layer Perceptron (MLP) with a hidden layer.\n",
    "  A two-layer network can correctly classify XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b124af-e6e4-4647-bd2b-11c7a75d698c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
