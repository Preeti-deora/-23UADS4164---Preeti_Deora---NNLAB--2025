{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9474d8-a4c9-4f3c-9e8f-345e01f5fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAND Predictions:\n",
      "Input: [0 0], Output: 1\n",
      "Input: [0 1], Output: 1\n",
      "Input: [1 0], Output: 1\n",
      "Input: [1 1], Output: 0\n",
      "\n",
      "XOR Predictions:\n",
      "Input: [0 0], Output: 1\n",
      "Input: [0 1], Output: 0\n",
      "Input: [1 0], Output: 0\n",
      "Input: [1 1], Output: 0\n",
      "\n",
      "NAND Perceptron Accuracy: 100.00%\n",
      "XOR Perceptron Accuracy: 25.00% (Fails for XOR)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def step_function(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction function\"\"\"\n",
    "        return np.array([self.step_function(np.dot(x, self.weights) + self.bias) for x in X])\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train Perceptron using Perceptron Learning Algorithm\"\"\"\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                y_pred = self.step_function(np.dot(X[i], self.weights) + self.bias)\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.lr * error * X[i]  # Update weights\n",
    "                self.bias += self.lr * error  # Update bias\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        correct = np.sum(predictions == y)\n",
    "        return correct / len(y) * 100  # Accuracy in percentage\n",
    "\n",
    "# NAND Dataset (Linearly Separable)\n",
    "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_nand = np.array([1, 1, 1, 0])  # NAND Truth Table\n",
    "\n",
    "# XOR Dataset (Not Linearly Separable)\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0])  # XOR Truth Table\n",
    "\n",
    "# Train Perceptron on NAND\n",
    "perceptron_nand = Perceptron(input_size=2, learning_rate=0.1, epochs=100)\n",
    "perceptron_nand.train(X_nand, y_nand)\n",
    "\n",
    "# Train Perceptron on XOR\n",
    "perceptron_xor = Perceptron(input_size=2, learning_rate=0.1, epochs=100)\n",
    "perceptron_xor.train(X_xor, y_xor)\n",
    "\n",
    "# Test NAND Predictions\n",
    "print(\"\\nNAND Predictions:\")\n",
    "for x in X_nand:\n",
    "    print(f\"Input: {x}, Output: {perceptron_nand.predict([x])[0]}\")\n",
    "\n",
    "# Test XOR Predictions\n",
    "print(\"\\nXOR Predictions:\")\n",
    "for x in X_xor:\n",
    "    print(f\"Input: {x}, Output: {perceptron_xor.predict([x])[0]}\")\n",
    "\n",
    "# Accuracy\n",
    "nand_accuracy = perceptron_nand.accuracy(X_nand, y_nand)\n",
    "xor_accuracy = perceptron_xor.accuracy(X_xor, y_xor)\n",
    "\n",
    "print(f\"\\nNAND Perceptron Accuracy: {nand_accuracy:.2f}%\")\n",
    "print(f\"XOR Perceptron Accuracy: {xor_accuracy:.2f}% (Fails for XOR)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f420dbf-e2b5-4c9a-9b67-debf4cc6d587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
