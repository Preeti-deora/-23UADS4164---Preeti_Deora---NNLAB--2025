{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3634ab0a-0d6b-4dd2-ac4c-0ecbc3415637",
   "metadata": {},
   "source": [
    "**Objective**:\n",
    "WAP to implement a multi-layer perceptron (MLP) network with one hidden layer \n",
    "using numpy in Python. Demonstrate that it can learn the XOR Boolean function.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d2cab-fc83-4827-b900-d9066d5c9ce5",
   "metadata": {},
   "source": [
    "**Model Description**\n",
    "Input Layer → 2 neurons (XOR inputs).\n",
    "Hidden Layer → 4 perceptrons with a step function activation.\n",
    "Output Layer → 1 perceptron with a step function activation.\n",
    "Learning Rate → 0.1\n",
    "Epochs → 100 (reduced for step-by-step tracking)\n",
    "Loss Calculation → Mean Squared Error (MSE).\n",
    "Evaluation Metrics → Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5476d9fc-2b31-4788-94ce-f84df660344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdcd0d1-df21-4ce6-a0bb-587f8a2eaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1, epochs=100):\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros(hidden_size)\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros(output_size)\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def step_function(self, x):\n",
    "        \"\"\"Step activation function\"\"\"\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.step_function(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.step_function(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        \"\"\"Backward pass using weight update rule\"\"\"\n",
    "        error = y - output  # Compute error\n",
    "\n",
    "        # Adjust weights using perceptron learning rule\n",
    "        self.W2 += self.lr * np.dot(self.a1.T, error)\n",
    "        self.b2 += self.lr * np.sum(error, axis=0)\n",
    "        self.W1 += self.lr * np.dot(X.T, np.dot(error, self.W2.T))\n",
    "        self.b1 += self.lr * np.sum(np.dot(error, self.W2.T), axis=0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the MLP\"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "            loss = np.mean((y - output) ** 2)  # Mean Squared Error\n",
    "            acc = self.accuracy(X, y)\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        return self.forward(X)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        correct = np.sum(predictions == y)\n",
    "        return correct / len(y) * 100  # Accuracy in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae596ca-1988-4541-b188-c64a213833e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR Dataset\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([[0], [1], [1], [0]])  # XOR Truth Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a2c75c4-0db0-4028-ad5c-3cdfe116860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 2/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 3/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 4/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 5/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 6/100, Loss: 0.2500, Accuracy: 75.00%\n",
      "Epoch 7/100, Loss: 0.2500, Accuracy: 75.00%\n",
      "Epoch 8/100, Loss: 0.2500, Accuracy: 75.00%\n",
      "Epoch 9/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 10/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 11/100, Loss: 0.2500, Accuracy: 75.00%\n",
      "Epoch 12/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 13/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 14/100, Loss: 0.2500, Accuracy: 75.00%\n",
      "Epoch 15/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 16/100, Loss: 0.5000, Accuracy: 50.00%\n",
      "Epoch 17/100, Loss: 0.5000, Accuracy: 50.00%\n",
      "Epoch 18/100, Loss: 0.5000, Accuracy: 50.00%\n",
      "Epoch 19/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 20/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 21/100, Loss: 0.5000, Accuracy: 50.00%\n",
      "Epoch 22/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 23/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 24/100, Loss: 0.5000, Accuracy: 75.00%\n",
      "Epoch 25/100, Loss: 0.2500, Accuracy: 75.00%\n",
      "Epoch 26/100, Loss: 0.2500, Accuracy: 50.00%\n",
      "Epoch 27/100, Loss: 0.5000, Accuracy: 50.00%\n",
      "Epoch 28/100, Loss: 0.5000, Accuracy: 100.00%\n",
      "Epoch 29/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 30/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 31/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 32/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 33/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 34/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 35/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 36/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 37/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 38/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 39/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 40/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 41/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 42/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 43/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 44/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 45/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 46/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 47/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 48/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 49/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 50/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 51/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 52/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 53/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 54/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 55/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 56/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 57/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 58/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 59/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 60/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 61/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 62/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 63/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 64/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 65/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 66/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 67/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 68/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 69/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 70/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 71/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 72/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 73/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 74/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 75/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 76/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 77/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 78/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 79/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 80/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 81/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 82/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 83/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 84/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 85/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 86/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 87/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 88/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 89/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 90/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 91/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 92/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 93/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 94/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 95/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 96/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 97/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 98/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 99/100, Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch 100/100, Loss: 0.0000, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "mlp = MLP(input_size=2, hidden_size=4, output_size=1, learning_rate=0.1, epochs=100)\n",
    "mlp.train(X_xor, y_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d926b935-6a9c-400a-8d68-54a4d6e871a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XOR Predictions:\n",
      "Input: [0 0], Output: [0]\n",
      "Input: [0 1], Output: [1]\n",
      "Input: [1 0], Output: [1]\n",
      "Input: [1 1], Output: [0]\n"
     ]
    }
   ],
   "source": [
    "# Test Predictions\n",
    "print(\"\\nXOR Predictions:\")\n",
    "for x in X_xor:\n",
    "    print(f\"Input: {x}, Output: {mlp.predict([x])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fcb273-8464-4776-bf7e-b48ce3439077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Final Accuracy\n",
    "accuracy = mlp.accuracy(X_xor, y_xor)\n",
    "print(f\"\\nFinal Model Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58323a-7970-4fec-9209-5a7b43735e41",
   "metadata": {},
   "source": [
    "**Description of the Code**\n",
    "1. Initialization (__init__)\n",
    "   Initializes weights & biases randomly for hidden and output layers.\n",
    "   Uses learning rate = 0.1 and epochs = 100.\n",
    "2. Activation (step_function)\n",
    "   Uses a step function to classify outputs as 0 or 1.\n",
    "3. Forward Propagation (forward)\n",
    "   Computes activations for hidden layer and output layer.\n",
    "4. Backward Propagation (backward)\n",
    "   Uses perceptron weight update rule to adjust weights & biases.\n",
    "5. Training (train)\n",
    "   Runs 100 epochs, printing loss & accuracy for each epoch.\n",
    "6. Prediction (predict)\n",
    "   Uses trained weights to classify new inputs.\n",
    "7. Accuracy Calculation (accuracy)\n",
    "   Compares predictions vs. actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48bbab-4e6c-473a-ab41-54e9977b2c9c",
   "metadata": {},
   "source": [
    "**Limitations**\n",
    "  Step function is non-differentiable, making learning inefficient.\n",
    "  Learning is slow due to basic weight update rule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
